# Automated Resume Delivery via AWS Lambda & API Gateway

This project is a fully automated infrastructure and deployment pipeline for serving resumes via a secured API. It uses AWS Lambda, API Gateway, DynamoDB + DynamoDB Streams and S3 - all provisioned via CloudFormation - and automatically deployed via GitHub Actions.

---

## Project Overview

This infrastructure allows you to:

- Upload a resume file to S3 via GitHub Actions
- Zip and deploy backend Lambda logic automatically
- Expose a POST REST API at `/resume` secured by an API Key
- Store Submission Information to be Referenced in DynamoDB Table
- Update code and infrastructure with every push to `main` or through `workflow_dispatch`

---

## Tech Stack

- **AWS CloudFormation** – Infrastructure as code (S3, Lambda, API Gateway, IAM)
- **AWS Lambda** – Python backend logic to serve your resume
- **API Gateway** – Public endpoint for clients to request the resume
- **DynamoDB** - Submission Information Storage + Event Trigger
- **S3** – Storage for your resume file and Lambda package
- **GitHub Actions** – Automated CI/CD pipeline for deploying infrastructure and code

---

##  Project Structure
<pre>```
.
├── .github/
│   └── workflows/
│       └── deploy.yaml                             # CI/CD pipeline
├── cloudformation/
│   ├── step1-createS3Bucket.yaml                   # CFN template to provision S3 bucket
│   └── step2-createDynamoDBTable.yaml              # CFN template to provision DynamoDB + DynamoDB Streams
│   ├── step3-createLambdaPostApiGatewayToDB.yaml   # CFN template to provision LambdaFunction Fronted Rest API Gateway
│   └── step4-lambdaReadDynamoDBStreams.yaml        # CFN template to provision Lambda Fronted by DynamoDB Streams
├── code/
│   └── index.py                                    # Lambda Function Code for Sending Resume via Email
├── pdfs/
│   └── your_resume.pdf                             # Resume to be uploaded to S3
├── TestSubmission/
│   └── local-test.php                              # PHP function which can be ran via XAMP or WAMP to test Submissions
``` </pre>

##  Deployment Workflow (CI/CD)

On every `push` to the `main` branch, GitHub Actions will:

1. **Validate** the CloudFormation templates.
2. **Check if the S3 bucket exists** — if not, it creates it.
3. **Create submissionsDB DynamoDB Table** 
4. **Creates Submission Handling Lambda**
5.    **Returns API Endpoint and ApiKeyID** - Can be Viewed in the Output
5. **Zip the Lambda code** in `code/` directory.
6. **Upload**:
   - `lambda.zip` → `s3://<your-bucket>/code/lambda.zip`
   - Resume file → `s3://<your-bucket>/pdfs/`
7. **Check if the Lambda function exists**:
   - If not: deploy full infra via CloudFormation.
   - If yes: skip infra deploy and just update the Lambda code.

---

## Secrets Required in GitHub Actions

| Secret Name              | Description |
|--------------------------|-------------|
| `APP_PASSWORD`           | SMTP Password generated by google for mailing service |
| `AWS_ACCESS_KEY_ID`      | IAM access key with CloudFormation, Lambda, S3 permissions |
| `AWS_REGION`             | AWS region (e.g., `us-east-1`) |
| `AWS_SECRET_ACCESS_KEY`  | IAM secret key |
| `S3_BUCKET_NAME`         | Target bucket name (`Will be used to Override Default BucketName`) Conditons: BucketName == `'^[a-z0-9.-]{3,63}$'` |
| `OBJECT_KEY`             | Filename of your resume (e.g., `pdfs/my_resume.pdf`) |
| `SENDER`                 | Information in json string format (e.g., `{"name":"Name","email":"Email","phone":"Phone","linkedInUrl":"LinkedInURL","githubUrl":"GithubURL"}`) |



---

## Lambda Handler

```python
# code/lambda.zip => index.py 

# High Level Overview of Core Code Functionality. 
def lambda_handler(event, context):
    sender_str = os.environ.get("SENDER")
    sender = json.loads(sender_str)
    requester = {}

    for record in event['Records']:
      new_image = record['dynamodb']
      body = new_image["NewImage"]
      requester['name'] = body.get('name').get('S')
      requester['email'] = body.get('email').get('S')

      msg = format_msg(sender, requester) # includes: resume_data = get_resume_from_s3() 
      send_email_with_attachment (sender, msg)

    return {
      'statusCode': 200,
      'body': 'Email with attachment sent successfully.'
      }
```
Customize this function to dynamically fetch metadata or trigger resume downloads.

## API Gateway Endpoint
Once deployed, your API will be available at: https://<api-id>.execute-api.<region>.amazonaws.com/prod/resume
API Keys Will be generated, but are stored secretly They can be retrieved using the AWS CLI
Note: Api_Key_ID will be outputted from step3-createLambdaPostApiGatewayToDB.yaml. Use the ID generated in place of <API_KEY_ID>

```bash
aws apigateway get-api-key \
  --api-key <API_KEY_ID> \ 
  --include-value \
  --region <your-region>
```

## Cloudformation Outputs
The deployment will print:

**step1-createS3Bucket.yaml**
- BucketName
- BucketArn

**step2-createDynamoDBTable.yaml**
- DynamoDBTableName (Exported)
- DynamoDBTableArn
- DynamoDBStreamArn (Exported)

**step3-createLambdaPostApiGatewayToDB.yaml**
- LambdaFunctionName 
- ApiGatewayUrl
- ApiKey 
- DynamoDBTableName 

**step3-createLambdaPostApiGatewayToDB.yaml**
- LambdaFunctionArn 

## License
MIT License. Use this as a boilerplate for your own resume, portfolio, or document-serving automation.